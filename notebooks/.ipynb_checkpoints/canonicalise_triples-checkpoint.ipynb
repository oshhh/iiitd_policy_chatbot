{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform coreference resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_text(filename):\n",
    "    raw_text = ''\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            raw_text += line\n",
    "    return raw_text\n",
    "\n",
    "def write_text(text, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        for line in text:\n",
    "            file.write(line)\n",
    "            \n",
    "def read_json(filename):\n",
    "    with open(filename) as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def write_json(data, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually define canonicals and replace in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_predefined_canonicals(triples, canonicals):\n",
    "    for sentence in triples:\n",
    "        for e in range(len(triples[sentence])):\n",
    "            for word in canonicals:\n",
    "                if triples[sentence][e]['subject'] in canonicals[word]:\n",
    "                    triples[sentence][e]['subject'] = word\n",
    "                for obj in range(len(triples[sentence][e]['object'])):\n",
    "                    if triples[sentence][e]['object'][obj] in canonicals[word]:\n",
    "                        triples[sentence][e]['object'][obj] = word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group canonicals and replace with one element of group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSU:\n",
    "    def __init__(self, array):\n",
    "# Code for DSU\n",
    "        self.parent = [i for i in range(len(array))]\n",
    "        self.size = [1 for i in range(len(array))]\n",
    "    def find(self, x):\n",
    "        p = x\n",
    "        while p != self.parent[p]:\n",
    "            p = self.parent[p]\n",
    "        temp = x\n",
    "        while temp != self.parent[temp]:\n",
    "            t = self.parent[temp]\n",
    "            self.parent[temp] = p\n",
    "            temp = t\n",
    "        return p \n",
    "\n",
    "    def combine(self, x, y):\n",
    "        x = self.find(x)\n",
    "        y = self.find(y)\n",
    "        if x == y:\n",
    "            return\n",
    "        if self.size[x] > self.size[y]:\n",
    "            self.parent[y] = x\n",
    "            self.size[x] += self.size[y]\n",
    "        else:\n",
    "            self.parent[x] = y\n",
    "            self.size[y] += self.size[x]\n",
    "\n",
    "# similar if word overlap is greater than 50%\n",
    "def similar(entity1, entity2):\n",
    "    words1 = list(set(entity1.split()))\n",
    "    words2 = list(set(entity2.split()))\n",
    "    common = 0\n",
    "    for word in words1:\n",
    "        common += words2.count(word)\n",
    "    return (2 * common > 0.5 * (len(words1) + len(words2)))\n",
    "\n",
    "\n",
    "def cluster_similar_words(triples):\n",
    "    # All entities\n",
    "    entities = set([])\n",
    "    for sentence in triples:\n",
    "        for extraction in triples[sentence]:\n",
    "            entities.add(extraction['subject'])\n",
    "            for obj in extraction['object']:\n",
    "                entities.add(obj)\n",
    "    entities = list(entities)\n",
    "\n",
    "    dsu = DSU(entities)\n",
    "\n",
    "    # combine similar words\n",
    "    for e1 in range(len(entities)):\n",
    "        for e2 in range(len(entities)):\n",
    "            if similar(entities[e1], entities[e2]):\n",
    "                dsu.combine(e1, e2)\n",
    "\n",
    "    parent_of_word = {}\n",
    "    for e in range(len(entities)):\n",
    "        parent_of_word[entities[e]] = entities[dsu.find(e)]\n",
    "\n",
    "    # replace entity by parent entity\n",
    "    for sentence in triples:\n",
    "        for e in range(len(triples[sentence])):\n",
    "            triples[sentence][e]['subject'] = parent_of_word[triples[sentence][e]['subject']]\n",
    "        for obj in range(len(triples[sentence][e]['object'])):\n",
    "            triples[sentence][e]['object'][obj] = parent_of_word[triples[sentence][e]['object'][obj]]\n",
    "    \n",
    "    for e in range(len(entities)):\n",
    "        entities[e] = parent_of_word[entities[e]]\n",
    "    print('original entities:', len(entities))\n",
    "    entities = list(set(entities))\n",
    "    print('reduced entities:', len(entities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create relation \"similar to\" between canonicals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark entity 1 as similar to the entity 2\n",
    "def get_similar_to_edges(triples):\n",
    "    # All entities\n",
    "    entities = set([])\n",
    "    for sentence in triples:\n",
    "        for extraction in triples[sentence]:\n",
    "            entities.add(extraction['subject'])\n",
    "            for obj in extraction['object']:\n",
    "                entities.add(obj)\n",
    "    entities = list(entities)\n",
    "    \n",
    "    similar_to_edges = []\n",
    "    for e1 in range(len(entities)):\n",
    "        for e2 in range(len(entities)):\n",
    "            if e1 == e2:\n",
    "                continue\n",
    "            if similar(entities[e1], entities[e2]):\n",
    "                similar_to_edges.append([entities[e1], 'similar to', entities[e2]])\n",
    "    \n",
    "    return similar_to_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canonicalisation using CESI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import requests\n",
    "\n",
    "API_ENDPOINT = \"https://www.wikidata.org/w/api.php\"\n",
    "\n",
    "def prepare_cesi_triples(triples, filename):\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    cesi_triples = []\n",
    "    id_ = 0\n",
    "    count_linked = 0\n",
    "    count_unlinked = 0\n",
    "    for sentence in triples:\n",
    "        for extraction in triples[sentence]:\n",
    "            # Get true link of the subject and object from wikidata\n",
    "            sub_true_link = requests.get(API_ENDPOINT, params = {\n",
    "                        'action': 'wbsearchentities',\n",
    "                        'format': 'json',\n",
    "                        'language': 'en',\n",
    "                        'search': extraction['subject']\n",
    "                    }).json()['search']\n",
    "            if len(sub_true_link) > 0:\n",
    "                sub_true_link = sub_true_link[0]['id']\n",
    "                count_linked += 1\n",
    "            else:\n",
    "                sub_true_link = None\n",
    "                count_unlinked += 1\n",
    "            ob_true_link = requests.get(API_ENDPOINT, params = {\n",
    "                        'action': 'wbsearchentities',\n",
    "                        'format': 'json',\n",
    "                        'language': 'en',\n",
    "                        'search': extraction['object']\n",
    "                    }).json()['search']\n",
    "            if len(ob_true_link) > 0:\n",
    "                ob_true_link = ob_true_link[0]['id']\n",
    "                count_linked += 1\n",
    "            else:\n",
    "                ob_true_link = None\n",
    "                count_unlinked += 1\n",
    "            print('sub:', extraction['subject'], sub_true_link, 'obj:', extraction['object'], ob_true_link)\n",
    "            triple = {\n",
    "                'id_': id_,\n",
    "                'triple': [\n",
    "                    extraction['subject'], \n",
    "                    extraction['relation'], \n",
    "                    extraction['object'][0]\n",
    "                ],\n",
    "                'triple_norm': [\n",
    "                    ' '.join([wordnet_lemmatizer.lemmatize(word) for word in extraction['subject'].split()]), \n",
    "                    ' '.join([wordnet_lemmatizer.lemmatize(word) for word in extraction['relation'].split()]), \n",
    "                    ' '.join([wordnet_lemmatizer.lemmatize(word) for word in extraction['object'][0].split()]), \n",
    "                ],\n",
    "                'true_link': {\n",
    "                    'subject': sub_true_link,\n",
    "                    'object': ob_true_link\n",
    "\n",
    "                },\n",
    "                'src_sentences': [sentence],\n",
    "                'entity_linking': {},\n",
    "                'kbp_info': []\n",
    "            }\n",
    "            id_ += 1\n",
    "            cesi_triples.append(triple)\n",
    "    write_text('\\n'.join([json.dumps(triple) for triple in cesi_triples]), filename)\n",
    "    print('linked:', count_linked, 'unlinked:', count_unlinked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub: courier boys vehicle None obj: ['main parking'] None\n",
      "sub: courier boys None obj: ['gf old building or reception'] None\n",
      "sub: courier boys None obj: ['security guard'] Q856887\n",
      "sub: courier boys None obj: ['no 1'] Q3346364\n",
      "sub: courier boys None obj: ['delivery of courier'] None\n",
      "sub: food items Q39342213 obj: ['delivery boy'] Q848466\n",
      "sub: food items Q39342213 obj: ['reception'] Q31948\n",
      "sub: food delivery boys vehicle None obj: ['main parking'] None\n",
      "sub: food delivery boys None obj: ['reception'] Q31948\n",
      "sub: food delivery boys None obj: ['delivery of food'] None\n",
      "sub: food items Q39342213 obj: ['delivery boy'] Q848466\n",
      "sub: visitor entry None obj: ['8'] Q23355\n",
      "sub: access and no courier boy details None obj: ['provided register'] None\n",
      "sub: visitor Q830719 obj: ['building complex'] Q1497364\n",
      "sub: visitors entering campus None obj: ['cctv surveillance and number plate'] None\n",
      "sub: campus Q209465 obj: ['self-driven cars'] Q58078234\n",
      "sub: visitor coming to building complex in chauffeur driven car None obj: ['same manner'] None\n",
      "sub: visitor Q830719 obj: ['building complex'] Q1497364\n",
      "sub: driver Q508846 obj: ['call'] Q353659\n",
      "sub: visitor Q830719 obj: ['intended destination'] None\n",
      "sub: visitor Q830719 obj: ['staff member'] Q47324772\n",
      "sub: his departure and time None obj: ['visitor register'] Q59927185\n",
      "sub: no 3 Q24632176 obj: ['faculty and staff and students using pathway and faculty visitors'] None\n",
      "sub: gate no 3 None obj: ['6'] Q23488\n",
      "sub: gate no 3 None obj: ['open'] Q2735683\n",
      "sub: no 3 Q24632176 obj: ['entry'] Q10389811\n",
      "sub: vehicles entering iiitd campus None obj: ['gate'] Q53060\n",
      "sub: their visitors None obj: ['gate'] Q53060\n",
      "sub: 1 . faculty None obj: ['iiitd campus'] None\n",
      "sub: overnight parking None obj: ['iiitd campus'] None\n",
      "sub: iiitd campus None obj: ['20 km or hr'] None\n",
      "sub: iiitd campus None obj: ['no horn zone and maximum speed of 20 km'] None\n",
      "sub: no horn zone and maximum speed of 20 km None obj: ['permissible'] Q4376583\n",
      "sub: vehicles Q7918612 obj: ['iiitd campus'] None\n",
      "sub: faculty or staff and students using their vehicles None obj: ['sticker of iiitd'] None\n",
      "sub: visitors vehicles None obj: ['main gate'] Q50808667\n",
      "sub: visitors vehicles None obj: ['entry'] Q10389811\n",
      "sub: visitors vehicles None obj: ['necessary registration'] None\n",
      "sub: necessary registration None obj: ['main gate'] Q50808667\n",
      "sub: necessary registration None obj: ['entry'] Q10389811\n",
      "sub: designated parking None obj: ['front of academic block'] None\n",
      "sub: vehicle Q42889 obj: ['faculty or officers or sc or security'] None\n",
      "sub: vehicle reported by faculty or officers or sc or security for violation of above guidelines None obj: ['rs 200'] Q2124609\n",
      "sub: helpdesk Q2055062 obj: ['email'] Q9158\n",
      "sub: complaints Q16514901 obj: ['facilities'] Q15761653\n",
      "sub: helpdesk executive None obj: ['complaint'] Q836925\n",
      "sub: such complaints None obj: ['complainant'] Q468489\n",
      "sub: sla Q869830 obj: ['24 hrs'] Q27827476\n",
      "sub: 24 hrs Q27827476 obj: ['other complaints of general nature'] None\n",
      "sub: ac and heating schedule None obj: ['https ://iiitd.ac.in/sites/default/files/docs/life/ac-schedule-for-hostels'] None\n",
      "sub: housekeeping staff Q77437062 obj: ['campus'] Q209465\n",
      "sub: housekeeping staff Q77437062 obj: ['two shifts'] Q76382199\n",
      "sub: housekeeping staff Q77437062 obj: ['4 pm'] Q41620578\n",
      "sub: housekeeping staff Q77437062 obj: ['available'] Q64678853\n",
      "sub: housekeeping staff Q77437062 obj: ['various areas which include hostel and dining block and academic and lecture block and library and external road area and and faculty residence'] None\n",
      "sub: floors Q99968674 obj: ['hostel'] Q654772\n",
      "sub: toilets Q7857 obj: ['hostel'] Q654772\n",
      "sub: stairs Q12511 obj: ['hostel'] Q654772\n",
      "sub: common rooms None obj: ['hostel'] Q654772\n",
      "sub: lifts Q99372 obj: ['hostel'] Q654772\n",
      "sub: floors Q99968674 obj: ['campus'] Q209465\n",
      "sub: toilets Q7857 obj: ['campus'] Q209465\n",
      "sub: glass Q11469 obj: ['campus'] Q209465\n",
      "sub: stairs Q12511 obj: ['campus'] Q209465\n",
      "sub: lifts Q99372 obj: ['campus'] Q209465\n",
      "sub: garbage Q45701 obj: ['campus'] Q209465\n",
      "sub: roads Q54229562 obj: ['campus'] Q209465\n",
      "sub: common areas Q35160876 obj: ['campus'] Q209465\n",
      "sub: labs and classrooms None obj: ['campus'] Q209465\n",
      "sub: fans and lights None obj: ['month'] Q5151\n",
      "sub: facade glass None obj: ['outside'] Q961258\n",
      "sub: schedule Q352858 obj: ['advance'] Q379156\n",
      "sub: fire drill Q3243704 obj: ['every semester'] None\n",
      "sub: dr . rk katharya b.sc and mbbs and fcpg None obj: ['monday'] Q105\n",
      "sub: dr . rk katharya b.sc and mbbs and fcpg None obj: ['our premises'] None\n",
      "sub: dr . rk katharya b.sc and mbbs and fcpg None obj: ['available'] Q64678853\n",
      "sub: neha dhiman None obj: ['mobile no'] Q48476446\n",
      "sub: neha Q16290822 obj: ['ext'] Q30007\n",
      "sub: neha dhiman None obj: ['monday'] Q105\n",
      "sub: neha dhiman None obj: ['available'] Q64678853\n",
      "linked: 93 unlinked: 67\n"
     ]
    }
   ],
   "source": [
    "canonicals = {\n",
    "    'hostel student': ['resident student', 'resident students', 'hostel student', 'hostel students', 'hostel resident', 'hostel residents', 'hosteller', 'hostellers'],\n",
    "    'student': ['student', 'students'],\n",
    "    'instructor': ['instructor', 'professor', 'faculty'],\n",
    "    'campus': ['campus', 'on campus', 'in campus', 'inside campus', 'iiitd', 'in iiitd', 'inside iiitd', 'iiitd campus', 'in iiitd campus', 'inside iiitd campus', 'in college', 'inside college']\n",
    "}\n",
    "\n",
    "triples = read_json('../data/ollie_triples.json')\n",
    "prepare_cesi_triples(triples, '../data/ollie_cesi_triples.txt')\n",
    "# replace_predefined_canonicals(triples, canonicals)\n",
    "# write_json(triples, '../data/ollie_canonicalised_1_triples.json')\n",
    "\n",
    "\n",
    "# triples = read_json('../data/ollie_triples.json')\n",
    "# cluster_similar_words(triples)\n",
    "# write_json(triples, '../data/ollie_canonicalised_2_triples.json')\n",
    "\n",
    "# triples = read_json('../data/ollie_triples.json')\n",
    "# similar_edges = get_similar_to_edges(triples)\n",
    "# print(similar_edges[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
